train_path = data/datasets/genia/genia_train_dev_context.json
valid_path = data/datasets/genia/genia_test_context.json
save_path = data/genia/main/
init_eval = False
save_optimizer = False
train_log_iter = 1
final_eval = False
train_batch_size = 6
epochs = 35
neg_entity_count = 5
neg_relation_count = 100
lr = 5e-06
lr_warmup = 0.1
weight_decay = 0.01
max_grad_norm = 1.0
iou_spn = 0.7
iou_classifier = 1.0
iou_weight = True
offset_loss = smoothl1loss
filter_loss = focalloss
entity_loss = focalloss
giou_loss = giouloss
filter_gamma = 2
entity_gamma = 2
offset_loss_weight = 1.0
filter_loss_weight = 1.0
entity_loss_weight = 1.0
giou_loss_weight = 1.0
iou_gamma = 1.0
config = configs/context_genia.conf
types_path = data/datasets/genia/genia_types.json
tokenizer_path = dmis-lab/biobert-large-cased-v1.1
window_size = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
lowercase = False
sampling_processes = 0
label = genia_train
log_path = data/genia/main/
store_predictions = True
store_examples = True
example_count = None
debug = False
device_id = 3
model_path = dmis-lab/biobert-large-cased-v1.1
model_type = identifier
cpu = False
eval_batch_size = 4
size_embedding = 25
prop_drop = 0.5
freeze_transformer = False
no_overlapping = False
nms = 0.45
lstm_drop = 0.2
lstm_layers = 1
pos_size = 25
spn_filter = 5.0
char_lstm_layers = 1
char_size = 50
char_lstm_drop = 0.2
use_glove = True
use_pos = True
use_char_lstm = True
pool_type = max
use_entity_ctx = True
wordvec_path = ../biovec/PubMed-shuffle-win-30.txt
use_size_embedding = False
reduce_dim = True
bert_before_lstm = True
no_filter = False
no_regressor = False
norm = sigmoid
no_times_count = False
seed = 47
cache_path = None

# train_path = data/datasets/ace05/ace05_train_context.json
# valid_path = data/datasets/ace05/ace05_test_context.json
# save_path = data/ace05/main/
# init_eval = False
# save_optimizer = False
# train_log_iter = 1
# final_eval = False
# train_batch_size = 8
# epochs = 35
# neg_entity_count = 5
# neg_relation_count = 100
# lr = 3e-05
# lr_warmup = 0.05
# weight_decay = 0.01
# max_grad_norm = 1.0
# iou_spn = 0.7
# iou_classifier = 1.0
# iou_weight = True
# offset_loss = smoothl1loss
# filter_loss = focalloss
# entity_loss = focalloss
# giou_loss = giouloss
# filter_gamma = 2
# entity_gamma = 2
# offset_loss_weight = 1.0
# filter_loss_weight = 1.0
# entity_loss_weight = 1.0
# giou_loss_weight = 1.0
# iou_gamma = 1.0
# config = configs/context_ace05.conf
# types_path = data/datasets/ace05/ace05_types.json
# tokenizer_path = bert-large-cased
# window_size = [0, 1, 2, 3, 4, 6, 8, 10, 12, 14]
# lowercase = False
# sampling_processes = 4
# label = ace05_train
# log_path = data/ace05/main/
# store_predictions = True
# store_examples = True
# example_count = None
# debug = False
# device_id = 0
# model_path = bert-large-cased
# model_type = identifier
# cpu = False
# eval_batch_size = 4
# size_embedding = 25
# prop_drop = 0.5
# freeze_transformer = False
# no_overlapping = False
# nms = 0.45
# lstm_drop = 0.4
# lstm_layers = 1
# pos_size = 25
# spn_filter = 5.0
# char_lstm_layers = 1
# char_size = 50
# char_lstm_drop = 0.2
# use_glove = True
# use_pos = True
# use_char_lstm = True
# pool_type = max
# use_entity_ctx = False
# wordvec_path = ../glove/glove.6B.100d.txt
# use_size_embedding = False
# reduce_dim = True
# bert_before_lstm = True
# no_filter = False
# no_regressor = False
# norm = sigmoid
# no_times_count = False
# seed = 47
# cache_path = None


# train_path = data/datasets3/kbp17/kbp17_train_context.json
# valid_path = data/datasets3/kbp17/kbp17_test_context.json
# save_path = data/kbp17/main/
# init_eval = False
# save_optimizer = False
# train_log_iter = 1
# final_eval = False
# train_batch_size = 4
# epochs = 30
# neg_entity_count = 5
# neg_relation_count = 100
# lr = 5e-05
# lr_warmup = 0.1
# weight_decay = 0.01
# max_grad_norm = 1.0
# iou_spn = 0.7
# iou_classifier = 1.0
# iou_weight = True
# offset_loss = smoothl1loss
# filter_loss = focalloss
# entity_loss = focalloss
# giou_loss = giouloss
# filter_gamma = 2
# entity_gamma = 2
# offset_loss_weight = 1.0
# filter_loss_weight = 0.1
# entity_loss_weight = 1.0
# giou_loss_weight = 1.0
# iou_gamma = 1.0
# config = configs/hp_kbp17.conf
# types_path = data/datasets3/kbp17/kbp17_types.json
# tokenizer_path = bert-large-cased
# window_size = [0, 1, 2, 3, 4, 6, 8, 10, 12, 14]
# lowercase = False
# sampling_processes = 0
# label = kbp17_train
# log_path = data/kbp17/main/
# store_predictions = True
# store_examples = True
# example_count = None
# debug = False
# device_id = 2
# model_path = bert-large-cased
# model_type = identifier
# cpu = False
# eval_batch_size = 4
# size_embedding = 25
# prop_drop = 0.2
# freeze_transformer = False
# no_overlapping = False
# nms = 0.5
# lstm_drop = 0.2
# lstm_layers = 2
# pos_size = 25
# spn_filter = 1.0
# char_lstm_layers = 1
# char_size = 50
# char_lstm_drop = 0.2
# use_glove = True
# use_pos = False
# use_char_lstm = True
# pool_type = max
# use_entity_ctx = False
# wordvec_path = ../glove/glove.6B.100d.txt
# use_size_embedding = False
# reduce_dim = True
# bert_before_lstm = False
# no_filter = False
# no_regressor = False
# norm = sigmoid
# no_times_count = False
# seed = 47
# cache_path = None


# train_path = data/datasets/ace04/ace04_train_context.json
# valid_path = data/datasets/ace04/ace04_test_context.json
# save_path = data/ace04/main/
# init_eval = False
# save_optimizer = False
# train_log_iter = 1
# final_eval = False
# train_batch_size = 8
# epochs = 35
# neg_entity_count = 5
# neg_relation_count = 100
# lr = 3e-05
# lr_warmup = 0.1
# weight_decay = 0.01
# max_grad_norm = 1.0
# iou_spn = 0.7
# iou_classifier = 1.0
# iou_weight = True
# offset_loss = smoothl1loss
# filter_loss = focalloss
# entity_loss = focalloss
# giou_loss = giouloss
# filter_gamma = 2
# entity_gamma = 2
# offset_loss_weight = 1.0
# filter_loss_weight = 0.1
# entity_loss_weight = 1.0
# giou_loss_weight = 1.0
# config = configs/context_ace04.conf
# types_path = data/datasets/ace04/ace04_types.json
# tokenizer_path = bert-large-cased
# window_size = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
# lowercase = False
# sampling_processes = 0
# label = ace04_train
# log_path = data/ace04/main/
# store_predictions = True
# store_examples = True
# example_count = None
# debug = False
# device_id = 1x
# model_path = bert-large-cased
# model_type = identifier
# cpu = False
# eval_batch_size = 4
# size_embedding = 25
# prop_drop = 0.5
# freeze_transformer = False
# no_overlapping = False
# nms = 0.45
# lstm_drop = 0.4
# lstm_layers = 1
# pos_size = 25
# spn_filter = 5
# char_lstm_layers = 1
# char_size = 50
# char_lstm_drop = 0.2
# use_glove = True
# use_pos = True
# use_char_lstm = True
# pool_type = max
# use_entity_ctx = True
# wordvec_path = ../glove/glove.6B.100d.txt
# use_size_embedding = False
# reduce_dim = True
# bert_before_lstm = True
# seed = 47
# cache_path = None